{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dog_Cat_Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CnuFxdk8lqj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "67dbfd93-7816-4500-b8b9-235453a6a945"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/Kaggle"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVtgkv4O8osZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0486925e-b20f-4a98-afaf-722ad13862e8"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\t      test\t train\t     train.zip\n",
            "sampleSubmission.csv  test1.zip  train_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9aCejcG9ekz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbdKTlCt9hkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "8e70c65a-2725-49a2-c9e2-e11603793f94"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from shutil import move\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "\n",
        "dir = '/content/drive/My Drive/Kaggle'\n",
        "folder = dir + '/train/'\n",
        "\n",
        "\n",
        "#Viewing first nine dogs in the dataset\n",
        "\n",
        "# for i in range(9):\n",
        "#     pyplot.subplot(330+1+i)\n",
        "#     pyplot.axis('off')\n",
        "#     filename = folder + 'dog.' + str(i) + '.jpg'\n",
        "#     image = imread(filename)\n",
        "#     pyplot.imshow(image)\n",
        "# pyplot.show()\n",
        "\n",
        "\n",
        "#Viewing first nine cats in the dataset\n",
        "\n",
        "# for i in range(9):\n",
        "#     pyplot.subplot(330+1+i)\n",
        "#     pyplot.axis('off')\n",
        "#     filename = folder + 'cat.' + str(i) + '.jpg'\n",
        "#     image = imread(filename)\n",
        "#     pyplot.imshow(image)\n",
        "# pyplot.show()\n",
        "\n",
        "\n",
        "#Pre-processing the images - Method 1\n",
        "\n",
        "# photos, labels = list(), list()\n",
        "# for file in os.listdir(folder):\n",
        "#     if file.startswith('cat'):\n",
        "#         output = 1.0\n",
        "#     else:\n",
        "#         output = 0.0\n",
        "#     photo = load_img(folder + file, target_size=(200,200))\n",
        "#     photo =img_to_array(photo)\n",
        "#     photos.append(photo) \n",
        "#     labels.append(output)\n",
        "# photos = np.asarray(photos)\n",
        "# labels = np.asarray(labels)\n",
        "# print(photos.shape, labels.shape)\n",
        "# np.save('/media/sam189239/Backup Plus/dogs_v_cats_photos.npy', photos)\n",
        "# np.save('/media/sam189239/Backup Plus/dogs_v_cats_labels.npy', labels)\n",
        "\n",
        "\n",
        "#Pre-processing the images - Method 2 (using ImageDataGenerator)\n",
        "random.seed(1)\n",
        "val_ratio = 0.25\n",
        "for file in os.listdir(folder):\n",
        "    src = folder + '/' + file\n",
        "    dst_folder = dir + '/train_data/'\n",
        "    if random.random()<val_ratio:\n",
        "        dst_folder = dir + '/test/'\n",
        "    if file.startswith('cat'):\n",
        "        dst = dst_folder+'cats/'+file\n",
        "        move(src,dst)\n",
        "    elif file.startswith('dog'):\n",
        "        dst = dst_folder+'dogs/'+file\n",
        "        move(src,dst)\n",
        "\n",
        "\n",
        "#define CNN Model\n",
        "\n",
        "# def define_model():\n",
        "#     model = Sequential()\n",
        "#     model.add(Conv2D(32, (3,3),activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', input_shape = (200, 200, 3)))\n",
        "#     model.add(MaxPooling2D((2,2)))\n",
        "#     model.add(Flatten())\n",
        "#     model.add(Dense(128, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
        "#     model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "#     opt = SGD(lr = 0.001, momentum = 0.9)\n",
        "#     model.compile(optimizer = opt, loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
        "#     return model\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\t# load model\n",
        "\tmodel = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
        "\t# mark loaded layers as not trainable\n",
        "\tfor layer in model.layers:\n",
        "\t\tlayer.trainable = False\n",
        "\t# add new classifier layers\n",
        "\tflat1 = Flatten()(model.layers[-1].output)\n",
        "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "\toutput = Dense(1, activation='sigmoid')(class1)\n",
        "\t# define new model\n",
        "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "\n",
        "#plot learning curves\n",
        "\n",
        "def plot_learning_curves(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\t#filename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(dir + '/_plot.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "\n",
        "#run test and evalute model\n",
        "\n",
        "def run_test():\n",
        "\tmodel = define_model()\n",
        "\tdatagen = ImageDataGenerator(featurewise_center=True)\n",
        "\tdatagen.mean = [123.68, 116.779, 103.939]\n",
        "    #iterators\n",
        "\ttrain_it = datagen.flow_from_directory(dir + '/train_data/', class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = datagen.flow_from_directory(dir + '/test/', class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "    #fit model\n",
        "\thist = model.fit(train_it, steps_per_epoch=len(train_it),\n",
        "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n",
        "    #evaluate model\n",
        "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\tplot_learning_curves(hist)\n",
        "\tmodel.save('final_model.h5')\n",
        " \n",
        "def run_test_16():\n",
        "# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(featurewise_center=True)\n",
        "\t# specify imagenet mean values for centering\n",
        "\tdatagen.mean = [123.68, 116.779, 103.939]\n",
        "\t# prepare iterator\n",
        "\ttrain_it = datagen.flow_from_directory(dir + '/train_data/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(224, 224))\n",
        "\t# fit model\n",
        "\tmodel.fit_generator(train_it, steps_per_epoch=len(train_it), epochs=10, verbose=0)\n",
        "\t# save model\n",
        "\tmodel.save('final_model_16.h5')\n",
        "\n",
        "run_test_16()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "Found 18697 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From <ipython-input-1-115abeaf16f2>:160: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r1pSJIt-8bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}